{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file all code (function and main to create and build the search engine)\n",
    "## this file contain olso the functions to merge the vocabulary_index, inverted_index and obtain the index of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "#nltk.download('stopwords') #decomment this lines if same errors tell to download this library\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Build your vocabulary and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(path_tsv):\n",
    "    for file in sorted(os.listdir(path_tsv)):#iteration over files\n",
    "        if file.startswith (\"article_\"): #check file is an article\n",
    "            with open(path_tsv+file, \"r\", encoding = \"utf-8\") as f:\n",
    "                text = f.read().lower() # read the file and trasform it in lowercase\n",
    "                words=cleaner(text) #--> func: cleaner\n",
    "                for w in words:\n",
    "                    if vocab.get(w, None)==None:#if v not in vocabulary: \n",
    "                        vocab[w]=len(vocab) #add it\n",
    "                        \n",
    "def cleaner(text):#input: a text to be clean:\n",
    "                    #output: a list of words of the text cleaned\n",
    "        \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    clean_text=\"\".join([ch if ch.isalnum() else \" \" for ch in text]) #trasform all non alnumeric character\n",
    "                                                                    #into a space\n",
    "    words = word_tokenize(clean_text) \n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # stemming of words\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(w) for w in words]\n",
    "    \n",
    "    return(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main \n",
    "# this take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation vocabolary done!\n",
      "vocabolario salvato correttamete!\n"
     ]
    }
   ],
   "source": [
    "vocab={}\n",
    "path='/home/tiago/Scrivania/Libri Magistrale/1st semester/ADM/HomeWork3/fileTsv/' #set the path to your tsv folder\n",
    "create_vocabulary(path) #--> function create_vocabulary\n",
    "print('creation vocabolary done!')\n",
    "with open('/home/tiago/Scrivania/Libri Magistrale/1st semester/ADM/HomeWork3/vocabulary.pkl', 'wb') as f:#set your path to save index\n",
    "        pickle.dump(vocab, f, pickle.HIGHEST_PROTOCOL) #open and safe vocabulary into a file\n",
    "print('vocabolario salvato correttamete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 ID of a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_document_html(file):#input: the name of the document; easy to obtain.. it's the file in: file in sorted(os.listdir(path))\n",
    "    if type(file)!=str:\n",
    "        raise Exception('file must have type str; {} obtained.'.format(type(file)))\n",
    "    start=len('article_')\n",
    "    return(int(file[start:-5])) #output: the number of the file\n",
    "\n",
    "def numer_document_tsv(file):#input: the name of the document; easy to obtain.. it's the file in: file in sorted(os.listdir(path))\n",
    "    if type(file)!=str:\n",
    "        raise Exception('file must have type str; {} obtained.'.format(type(file)))\n",
    "    start=len('article_')\n",
    "    return(int(file[start:-4])) #output: the number of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Build the inverted_index and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_tsv_files_update_index(path_tsv): #input: the path where the file tsv are\n",
    "    for file in sorted(os.listdir(path_tsv)):\n",
    "        #print('sto pulendo il file: {}'.format(file))\n",
    "        if file.startswith(\"article_\"):\n",
    "            with open(path_tsv+file, \"r\", encoding = \"utf-8\") as f:\n",
    "                text = f.read().lower() # read the file                                           \n",
    "                clean_text_words=cleaner(text) #clean the text\n",
    "                updateIndex(clean_text_words, file) #--> updateIndex\n",
    "                    \n",
    "def updateIndex(listOfWords, fileName):\n",
    "    num_doc=numer_document_tsv(fileName) #retrive the number of the file\n",
    "    for word in listOfWords:\n",
    "        num_word=vocab[word] #retrive the number of the word\n",
    "        posts=index.get(num_word, None)#try to obtain the value of the word key:\n",
    "        if posts==None: #if it is absent\n",
    "            index[num_word]={num_doc:1} #add the key with value a dictionary{doc: frequenzy}\n",
    "        else:\n",
    "            post=index[num_word].get(num_doc, None)# otherwise try to obtain the value of the document key\n",
    "            if post==None: #if it's absent:\n",
    "                index[num_word][num_doc]=1 #add the document key with frequency 1\n",
    "            else:\n",
    "                index[num_word][num_doc]+=1#:otherwise update the last value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverted index creato correttamete!\n",
      "invert index salvato correttamete!\n"
     ]
    }
   ],
   "source": [
    "index={}\n",
    "path_tsv='/home/tiago/Scrivania/Libri Magistrale/1st semester/ADM/HomeWork3/fileTsv/'\n",
    "path_index='/home/tiago/Scrivania/Libri Magistrale/1st semester/ADM/HomeWork3/inverted_index.pkl'\n",
    "#set your path\n",
    "\n",
    "\n",
    "cleaner_tsv_files_update_index(path_tsv) #cleane tsv file\n",
    "print('inverted index creato correttamete!')\n",
    "\n",
    "\n",
    "with open(path_index, 'wb') as f: # and save index into a file\n",
    "        pickle.dump(index, f, pickle.HIGHEST_PROTOCOL)\n",
    "print('invert index salvato correttamete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "131875 131875\n",
      "28509\n"
     ]
    }
   ],
   "source": [
    "print(set(index.keys()) - set(vocab.values()))\n",
    "print(len(index), len(vocab))\n",
    "#with open('prova.txt', 'w') as f:\n",
    "#    print(index, file=f)\n",
    "len(index[4])\n",
    "print(len(index[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
